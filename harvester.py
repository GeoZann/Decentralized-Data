import os
import pandas as pd
import datetime
import requests  
import time
from kaggle.api.kaggle_api_extended import KaggleApi
from pymongo import MongoClient

# --- Î¡Î¥Î˜ÎœÎ™Î£Î•Î™Î£ BÎ‘Î£Î—Î£ ---
MONGO_URI = "mongodb+srv://Giorgos:root@cluster0.c940dbb.mongodb.net/?appName=Cluster0"
DB_NAME = "CourseDB"
COLLECTION_NAME = "courses"

# Î£ÏÎ½Î´ÎµÏƒÎ· Î¼Îµ MongoDB (Î“Î¯Î½ÎµÏ„Î±Î¹ Î¼Î¯Î± Ï†Î¿ÏÎ¬ Î­Î¾Ï‰ Î±Ï€ÏŒ Ï„Î¹Ï‚ ÏƒÏ…Î½Î±ÏÏ„Î®ÏƒÎµÎ¹Ï‚)
client = MongoClient(MONGO_URI)
db = client[DB_NAME]
collection = db[COLLECTION_NAME]

# ==========================================
# Î›Î•Î™Î¤ÎŸÎ¥Î¡Î“Î™Î‘ 1: HARVEST EDX (Î‘Ï€ÏŒ Kaggle CSV)
# ==========================================
def harvest_edx():
    print("\nğŸŸ¦ [EDX] ÎÎµÎºÎ¹Î½Î¬ÎµÎ¹ Î· Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯Î± harvesting...")
    DATASET = "imuhammad/edx-courses"
    DOWNLOAD_PATH = "./data"
    
    try:
        api = KaggleApi()
        api.authenticate()
        api.dataset_download_files(DATASET, path=DOWNLOAD_PATH, unzip=True)
        
        csv_file = None
        for file in os.listdir(DOWNLOAD_PATH):
            if file.endswith(".csv") and "edx" in file.lower():
                csv_file = os.path.join(DOWNLOAD_PATH, file)
                break
        
        if not csv_file:
            print("âŒ [EDX] Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ CSV Î±ÏÏ‡ÎµÎ¯Î¿.")
            return

        df = pd.read_csv(csv_file)
        df = df.fillna("")
        
        count = 0
        for index, row in df.iterrows():
            course_data = {
                "title": row.get("title"),
                "description": row.get("course_description") or row.get("summary"),
                "category": row.get("subject"),
                "level": row.get("Level"),
                "original_url": row.get("course_url"),
                "source_repository": "edX",
                "language": row.get("language") or "en",
                "last_updated": datetime.datetime.now(),
                "cluster": None
            }
            
            if save_to_mongo(course_data):
                count += 1
                
        print(f"âœ… [EDX] ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ! Î ÏÎ¿ÏƒÏ„Î­Î¸Î·ÎºÎ±Î½/Î•Î½Î·Î¼ÎµÏÏÎ¸Î·ÎºÎ±Î½ {count} Î¼Î±Î¸Î®Î¼Î±Ï„Î±.")
        
    except Exception as e:
        print(f"âŒ [EDX] Î£Ï†Î¬Î»Î¼Î±: {e}")

# ==========================================
# Î›Î•Î™Î¤ÎŸÎ¥Î¡Î“Î™Î‘ 2: HARVEST COURSERA (Î‘Ï€ÏŒ Hugging Face API)
# ==========================================
def harvest_coursera():
    print("\nğŸŸ¨ [COURSERA] ÎÎµÎºÎ¹Î½Î¬ÎµÎ¹ Î· Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯Î± harvesting Î±Ï€ÏŒ API...")
    
    # Î¤Î¿ Î²Î±ÏƒÎ¹ÎºÏŒ URL Ï‡Ï‰ÏÎ¯Ï‚ Ï„Î¹Ï‚ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÎ¿Ï…Ï‚
    base_url = "https://datasets-server.huggingface.co/rows"
    params = {
        "dataset": "azrai99/coursera-course-dataset",
        "config": "default",
        "split": "train",
        "offset": 0,
        "length": 100 # Î Î±Î¯ÏÎ½Î¿Ï…Î¼Îµ 100 Ï„Î· Ï†Î¿ÏÎ¬
    }
    
    total_count = 0
    has_more_data = True
    
    while has_more_data:
        try:
            print(f"   â³ Î›Î®ÏˆÎ· Î¼Î±Î¸Î·Î¼Î¬Ï„Ï‰Î½ {params['offset']} - {params['offset'] + 100}...")
            response = requests.get(base_url, params=params)
            
            if response.status_code != 200:
                print(f"âŒ [COURSERA] API Error: {response.status_code}")
                break
                
            data = response.json()
            rows = data.get("rows", [])
            
            if not rows:
                has_more_data = False
                break
                
            # Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Ï„Ï‰Î½ 100 ÎµÎ³Î³ÏÎ±Ï†ÏÎ½
            for item in rows:
                row = item["row"] # Î¤Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÎµÎ¯Î½Î±Î¹ Î¼Î­ÏƒÎ± ÏƒÏ„Î¿ ÎºÎ»ÎµÎ¹Î´Î¯ "row"
                
                # Mapping (Î ÏÎ¿ÏƒÎ±ÏÎ¼Î¿Î³Î® ÏƒÏ„Î± Î´Î¹ÎºÎ¬ Î¼Î±Ï‚ Ï€ÎµÎ´Î¯Î±)
                course_data = {
                    "title": row.get("title"),
                    "skills": row.get("Skills"),
                    "description": row.get("Description") or row.get("Course Name"),
                    "category": "General", # Î¤Î¿ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î¿ dataset Î¯ÏƒÏ‰Ï‚ Î´ÎµÎ½ Î­Ï‡ÎµÎ¹ category, Î²Î¬Î¶Î¿Ï…Î¼Îµ General
                    "level": row.get("Level"),
                    "original_url": row.get("URL"),
                    "source_repository": "Coursera",
                    "language": "en", # Î¥Ï€Î¿Î¸Î­Ï„Î¿Ï…Î¼Îµ Î±Î³Î³Î»Î¹ÎºÎ¬
                    "last_updated": datetime.datetime.now(),
                    "cluster": None
                }
                
                if save_to_mongo(course_data):
                    total_count += 1
            
            # Î ÏÎ¿ÎµÏ„Î¿Î¹Î¼Î±ÏƒÎ¯Î± Î³Î¹Î± Ï„Î·Î½ ÎµÏ€ÏŒÎ¼ÎµÎ½Î· ÏƒÎµÎ»Î¯Î´Î±
            params["offset"] += 100
            time.sleep(3) # ÎœÎ¹ÎºÏÎ® ÎºÎ±Î¸Ï…ÏƒÏ„Î­ÏÎ·ÏƒÎ· Î³Î¹Î± Î½Î± Î¼Î·Î½ "Î¸Ï…Î¼ÏÏƒÎµÎ¹" Ï„Î¿ API
            
        except Exception as e:
            print(f"âŒ [COURSERA] Î£Ï†Î¬Î»Î¼Î± ÏƒÏ„Î¿ loop: {e}")
            break
            
    print(f"âœ… [COURSERA] ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ! Î ÏÎ¿ÏƒÏ„Î­Î¸Î·ÎºÎ±Î½/Î•Î½Î·Î¼ÎµÏÏÎ¸Î·ÎºÎ±Î½ {total_count} Î¼Î±Î¸Î®Î¼Î±Ï„Î±.")

# ==========================================
# Î’ÎŸÎ—Î˜Î—Î¤Î™ÎšÎ— Î£Î¥ÎÎ‘Î¡Î¤Î—Î£Î— Î‘Î ÎŸÎ˜Î—ÎšÎ•Î¥Î£Î—Î£
# ==========================================
def save_to_mongo(data):
    # Î‘Ï€Î¿Î¸Î·ÎºÎµÏÎ¿Ï…Î¼Îµ Î¼ÏŒÎ½Î¿ Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Ï„Î¯Ï„Î»Î¿Ï‚ ÎºÎ±Î¹ URL
    if data["title"] and data["original_url"]:
        collection.update_one(
            {"original_url": data["original_url"]},
            {"$set": data},
            upsert=True
        )
        return True
    return False

# ==========================================
# MAIN EXECUTION
# ==========================================
if __name__ == "__main__":
    # Î¤ÏÎ­Ï‡Î¿Ï…Î¼Îµ ÎºÎ±Î¹ Ï„Î± Î´ÏÎ¿!
    harvest_edx()
    harvest_coursera()
    
    print("\nâœ¨ ÎŸÎ›Î‘ Î¤Î•Î›Î•Î™Î©Î£Î‘Î! Î— Î²Î¬ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ÎµÎ¯Î½Î±Î¹ Ï€Î»Î®ÏÏ‰Ï‚ ÎµÎ½Î·Î¼ÎµÏÏ‰Î¼Î­Î½Î·.")